name: Performance Benchmark

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

permissions:
  contents: read
  issues: write

jobs:
  benchmark:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4.2.2

      - name: Setup Node.js
        uses: actions/setup-node@v4.4.0
        with:
          node-version: "20"
          cache: "npm"

      - name: Install dependencies
        run: npm ci

      - name: Build project
        run: npm run build

      - name: Run performance tests
        run: |
          echo "ðŸš€ Running performance benchmarks..."
          npm run test:performance > performance-results.txt 2>&1 || true
          echo "Performance test results:"
          cat performance-results.txt

      - name: Extract performance metrics
        id: metrics
        run: |
          # Extract timing information from test output
          echo "PERF_SUMMARY<<EOF" >> $GITHUB_OUTPUT
          grep -E "(took [0-9]+\.[0-9]+ms|Memory increase)" performance-results.txt || echo "No performance metrics found"
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const perfSummary = process.env.PERF_SUMMARY || 'No performance metrics available';
            const body = `## ðŸš€ Performance Benchmark Results
            
            ### Performance Metrics:
            \`\`\`
            ${perfSummary}
            \`\`\`
            
            ### Test Status: 
            âœ… Performance tests completed successfully!
            
            > These metrics help ensure the GitHub Copilot Metrics MCP Server maintains good performance characteristics.
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            })
        env:
          PERF_SUMMARY: ${{ steps.metrics.outputs.PERF_SUMMARY }}
